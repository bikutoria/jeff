{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dd83f94e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, random, sys, time\n",
    "from selenium import webdriver\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from math import pi\n",
    "\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "\n",
    "import time \n",
    "from operator import length_hint \n",
    "\n",
    "from selenium.common.exceptions import NoSuchElementException"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6e1e17a0-4596-42ee-819c-20c4638025c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "browser = webdriver.Chrome('Documents/Driver/chromedriver')    \n",
    "\n",
    "browser.get('https://www.linkedin.com/uas/login')\n",
    "\n",
    "file = open('Documents/Config.txt')\n",
    "lines = file.readlines()\n",
    "username = lines[0]\n",
    "password = lines[1]\n",
    "\n",
    "elementID = browser.find_element_by_id('username')\n",
    "elementID.send_keys(username)\n",
    "\n",
    "elementID = browser.find_element_by_id('password')\n",
    "elementID.send_keys(password)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1b8c8e11-91f8-487d-a8fa-91f09d4959dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "elementID.submit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f7e431b0-258c-4297-9538-ffb775eacbd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "visitingcompany = '/search/results/people/?currentCompany=%5B\"33223\"%5D&'\n",
    "fulllink = 'https://www.linkedin.com' + visitingcompany\n",
    "browser.get(fulllink)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "855dd64b-eb29-4675-a021-f50f87c8f18c",
   "metadata": {},
   "outputs": [],
   "source": [
    "profilesqueued = []\n",
    "\n",
    "def getnewprofile(soup, profilesqueued):\n",
    "    ProfilesID = []\n",
    "    pav = soup.find('div', {'class':'ph0 pv2 artdeco-card mb2'})\n",
    "    profilelink = soup.findAll('a', {'aria-hidden':'false'})\n",
    "    for links in profilelink:\n",
    "        userLink = links.get('href')\n",
    "        profilesqueued.append(userLink)\n",
    "    return (userLink)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f8dccaa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This code allows scraping all linkedIn profiles as it is flipping to the next page\n",
    "try:\n",
    "    x = 0\n",
    "    while True:\n",
    "        browser.execute_script(\"window.scrollTo(0, 10000);\")\n",
    "        time.sleep(1)\n",
    "        (getnewprofile(BeautifulSoup(browser.page_source), profilesqueued))\n",
    "        nextpage = browser.find_element_by_xpath(\"//button[@class='artdeco-pagination__button artdeco-pagination__button--next artdeco-button artdeco-button--muted artdeco-button--icon-right artdeco-button--1 artdeco-button--tertiary ember-view']\").click()\n",
    "        time.sleep(1)\n",
    "        x += 1\n",
    "except NoSuchElementException:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6198458a-ba00-4713-af8c-bb9a5b313074",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns=['employee_name', 'Current_title', 'company_name1','company_name2']\n",
    "df = pd.DataFrame(columns=columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a2168e71-a002-421b-9c2a-7c896e92bf42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraping Stopped!!!\n"
     ]
    }
   ],
   "source": [
    "x = 1\n",
    "try:\n",
    "    while x < len(profilesqueued):\n",
    "        browser.get(profilesqueued[x])\n",
    "\n",
    "        Name = []\n",
    "        Currenttitle = []\n",
    "        Company1 = []\n",
    "        Company2 = []\n",
    "\n",
    "        source = browser.page_source\n",
    "        soup = BeautifulSoup(source, 'lxml')\n",
    "        \n",
    "        #Get Employee Name\n",
    "        \n",
    "        employee_name_section_div = soup.find('div',{'class':'pv-text-details__left-panel mr5'})\n",
    "        employee_name = employee_name_section_div.find('h1',{'class':'text-heading-xlarge inline t-24 v-align-middle break-words'}).get_text().strip()\n",
    "\n",
    "        Name.append(employee_name)\n",
    "        \n",
    "        experience_section = browser.find_element(By.XPATH, '//*[@id=\"experience-section\"]/header/h2')\n",
    "        browser.execute_script(\"arguments[0].scrollIntoView();\",experience_section)\n",
    "        \n",
    "        \n",
    "        #Get Current Company Title\n",
    "        \n",
    "        Current_title_li = soup.findAll('li',{'class':'pv-entity__position-group-pager pv-profile-section__list-item ember-view'})\n",
    "        try:\n",
    "            Current_title = Current_title_li[0].find('h3',{'class':'t-16 t-black t-bold'}).get_text().strip()\n",
    "        except:\n",
    "            Current_title=None\n",
    "\n",
    "        Currenttitle.append(Current_title)\n",
    "        \n",
    "        \n",
    "        #Get Previous Company Name 1\n",
    "\n",
    "        company_name_li = soup.findAll('li',{'class':'pv-entity__position-group-pager pv-profile-section__list-item ember-view'})\n",
    "        try:\n",
    "            company_name1 = company_name_li[1].find('p',{'class':'pv-entity__secondary-title t-14 t-black t-normal'}).get_text().strip()\n",
    "        except:\n",
    "            company_name1=None\n",
    "\n",
    "        Company1.append(company_name1)\n",
    "        \n",
    "        \n",
    "        #Get Previous Company Name 1\n",
    "\n",
    "        company_name_li = soup.findAll('li',{'class':'pv-entity__position-group-pager pv-profile-section__list-item ember-view'})\n",
    "        try:\n",
    "            company_name2 = company_name_li[2].find('p',{'class':'pv-entity__secondary-title t-14 t-black t-normal'}).get_text().strip()\n",
    "        except:\n",
    "            company_name2 = None\n",
    "\n",
    "        Company2.append(company_name2)\n",
    "\n",
    "        \n",
    "        time.sleep(1)\n",
    "\n",
    "        \n",
    "        df=df.append({ 'employee_name' : employee_name, 'Current_title' : Current_title ,'company_name1' : company_name1, 'company_name2' : company_name2 } ,ignore_index=True)\n",
    "        x += 1\n",
    "except NoSuchElementException:\n",
    "    pass \n",
    "print (\"Scraping Stopped!!!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "4f640cc9-bbf7-4ae0-aa04-232335adef27",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-154-60e6ee5871b5>:1: FutureWarning: As the xlwt package is no longer maintained, the xlwt engine will be removed in a future version of pandas. This is the only engine in pandas that supports writing in the xls format. Install openpyxl and write to an xlsx file instead. You can set the option io.excel.xls.writer to 'xlwt' to silence this warning. While this option is deprecated and will also raise a warning, it can be globally set and the warning suppressed.\n",
      "  df.to_excel('Desktop/Excel Bot Output/LinkedIn Profiles with Job Title.xls', index = False, header=True)\n"
     ]
    }
   ],
   "source": [
    "df.to_excel('Desktop/Excel Bot Output/LinkedIn Profiles with Job Title.xls', index = False, header=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "fdfdb629-9a43-4478-9390-c2a46ca495ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "del df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "eee278b4-afd6-4725-ab98-c946cca2e217",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-23-00cf07b74dcd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb68a346-a890-432b-9a2b-e7d3a764be6b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14479c5f-f9a6-481f-82fd-08fda8f2d08f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3f46487-cde5-4a14-bfff-d89dcef75fc6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
